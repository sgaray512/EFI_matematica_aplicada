---
title: "EFI: COVID-19 Argentina"
author: "Garay Santiago, Ivan Escobar, Villavicencio Jonatan, Ibarra Matias"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    theme: yeti
    df_print: paged
    code_folding: hide
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center", fig.width = 9, fig.height = 5)

separador <- function() {
  cat("_______________________________________________________________\n\n")
}

required <- c(
"data.table","dplyr","lubridate","ggplot2","xgboost","Metrics",
"zoo","tidyr","scales","patchwork",
"mlbench","caret","e1071",
"kableExtra","broom"
)

installed <- rownames(installed.packages())
new <- required[!(required %in% installed)]
if(length(new)) install.packages(new, dependencies = TRUE)
lapply(required, library, character.only = TRUE)
```

# Introducción
Este R Markdown contiene el pipeline completo para un proyecto de predicción de **nuevos casos diarios de COVID-19** en **Argentina**, usando el dataset completo de Our World in Data (`owid-covid-data.csv`).

Objetivo: predecir `new_cases` a 14 días con fundamento y medición de la confiabilidad del modelo. Se busca modelar casos diarios, entender correlaciones y construir un modelo de predicción.

---

# Carga y filtrado de datos
En este paso se carga la base de datos completa de COVID-19.  
Luego filtramos únicamente para el país seleccionado ("Argentina") y construimos un dataset con las variables de interés.
```{r filtrado}
separador()

pais <- "Argentina"

file_path <- "~/Descargas/owid-covid-data.csv"
raw <- fread(file_path)

df <- raw %>%
filter(location == "Argentina") %>%
select(date,new_cases,new_deaths,total_cases,total_deaths,population,new_tests) %>%
mutate(date = as.Date(date),
new_cases = replace_na(new_cases,0),
new_tests = replace_na(new_tests,0))
```
---

# Exploración inicial y gráficos
En esta sección analizamos cómo evolucionaron los casos diarios y los tests en el país seleccionado.
Podemos observar tendencias, estacionalidades y posibles anomalías en los datos.
```{r series}
separador()

p1 <- ggplot(df, aes(date,new_cases)) + geom_line() + theme_minimal() +
labs(title="Nuevos casos diarios", x="Fecha", y="Casos")

p2 <- ggplot(df, aes(date,new_tests)) + geom_line() + theme_minimal() +
labs(title="Tests diarios", x="Fecha", y="Tests")

p1 / p2
```

# Distribución
```{r distribucion}
separador()
qplot(df$new_cases, bins=80) + scale_x_continuous(labels = comma)
```

# Correlación y autocorrelación
```{r correlacion}
separador()

df <- df %>%
mutate(cases_per_100k = new_cases/population*1e5,
tests_per_100k = new_tests/population*1e5)

corr_tab <- df %>%
select(new_cases,new_deaths,total_cases,total_deaths,cases_per_100k,tests_per_100k) %>%
drop_na() %>% cor()

kable(corr_tab, caption="Matriz de correlaciones") %>% kable_styling()

separador()
acf(df$new_cases, main="Autocorrelación (ACF) de nuevos casos")

```

# Feature engineering
Aquí evaluamos si existe relación entre los casos diarios y la cantidad de tests.
Esto es importante para justificar si una regresión lineal tiene sentido.
```{r features}
separador()

for(lag in c(1,7,14)){
df[[paste0("lag_cases_",lag)]] <- dplyr::lag(df$new_cases,n=lag)
}

df$ma7_cases  <- rollmean(df$new_cases,k=7, fill=NA)
df$ma14_cases <- rollmean(df$new_cases,k=14, fill=NA)

df_model <- df %>% filter(!is.na(lag_cases_14))
```

# Regresión lineal
Ajustamos un modelo lineal donde:
- Variable dependiente (Y): Nuevos casos diarios
- Variable independiente (X): Tests diarios

Esto nos permite analizar el grado de influencia y significancia estadística.
```{r regresion-lineal}
separador()

# Ajuste del modelo lineal

lm_fit <- lm(new_cases ~ new_tests, data = df_model)

# Resumen del modelo

lm_summary <- summary(lm_fit)

# Coeficiente de determinación R²

r2 <- lm_summary$r.squared

# Tabla de coeficientes con broom

coef_tab <- broom::tidy(lm_fit) %>%
mutate(across(where(is.numeric), ~round(.,4))) %>%
rename(Estimate = estimate,
StdError = std.error,
t = statistic,
Pvalue = p.value)

kable(coef_tab, caption="Tabla de coeficientes del modelo lineal") %>%
kable_styling(full_width=FALSE)

# Gráfico con recta de regresión

ggplot(df_model, aes(new_tests, new_cases)) +
geom_point(alpha=0.4) +
geom_smooth(method="lm", se=TRUE, color="blue") +
annotate("text", x=Inf, y=Inf, hjust=1.2, vjust=2,
label=paste0("R² = ", round(r2,3),
"\np = ", signif(coef_tab$Pvalue[2],3))) +
theme_minimal() +
labs(title="Regresión lineal: Nuevos casos vs Tests",
x="Tests diarios", y="Nuevos casos")
```

# Anova
```{r anova}
separador()

lm_anova <- anova(lm_fit)

kable(lm_anova, caption="Tabla ANOVA del modelo lineal") %>%
kable_styling(full_width=FALSE)
```

# División temporal: train / val / test
Para entrenar y evaluar correctamente un modelo predictivo en **series temporales**, no podemos hacer una división aleatoria de los datos (como se haría en problemas tradicionales).  
En cambio, debemos respetar el **orden cronológico**, porque el modelo solo puede aprender del pasado para predecir el futuro.

Por eso, dividimos el dataset en tres subconjuntos:

- **Train (entrenamiento):** datos históricos iniciales.  
  El modelo aprende aquí las relaciones y patrones.
  
- **Validation (validación):** período inmediatamente posterior al train.  
  Se usa para ajustar hiperparámetros y evitar sobreajuste.
  
- **Test (prueba):** los últimos días de la serie.  
  Se usa únicamente para medir el desempeño real del modelo frente a datos nuevos.

Esta división imita el proceso real de predicción: siempre usamos el pasado para anticipar el futuro.
```{r split}
separador()

total <- nrow(df_model)
n_test <- 14; n_val <- 14; n_train <- total - n_val - n_test

train <- df_model[1:n_train,]
val   <- df_model[(n_train+1):(n_train+n_val),]
test  <- df_model[(n_train+n_val+1):total,]
```

# Modelado: XGBoost (regresión)
```{r xgb}
separador()

features <- c("lag_cases_1","lag_cases_7","lag_cases_14","ma7_cases","ma14_cases","cases_per_100k","tests_per_100k")
features <- features[features %in% names(df_model)]

dtrain <- xgb.DMatrix(as.matrix(train[, ..features]), label = train$new_cases)
dval   <- xgb.DMatrix(as.matrix(val[, ..features]),   label = val$new_cases)

model <- xgb.train(
list(objective="reg:squarederror",eval_metric="rmse",eta=0.1,max_depth=6),
data=dtrain,
nrounds=500,
watchlist=list(val=dval),
early_stopping_rounds=20,
verbose=0
)

xgb.importance(model=model)
```

# Evaluación en validación y test
```{r eval}
separador()

pred_val  <- predict(model,dval)
pred_test <- predict(model, xgb.DMatrix(as.matrix(test[, ..features])))

cat("RMSE val:", rmse(val$new_cases,pred_val), "\n")
cat("RMSE test:", rmse(test$new_cases,pred_test), "\n")
```

# Predicción a futuro (14 días) — enfoque iterativo
```{r forecast}
h <- 14
pais <- "Argentina"

last_data <- df_model[nrow(df_model), ]
prev_window <- tail(df_model, 30)

future <- data.table(date = seq(last_data$date + 1, by = "day", length.out = h))

for(i in 1:h){
  
  lag1 <- if(i==1) tail(prev_window$new_cases,1) else future$pred[i-1]
  lag7 <- if(nrow(prev_window) >= 7) tail(prev_window$new_cases,7)[1] else lag1
  
  ma7  <- mean(tail(c(prev_window$new_cases, future$pred[1:(i-1)]),7),  na.rm=TRUE)
  ma14 <- mean(tail(c(prev_window$new_cases, future$pred[1:(i-1)]),14), na.rm=TRUE)

  cases_pk <- lag1 / last_data$population * 1e5

  vec <- c(lag_cases_1 = lag1, lag_cases_7 = lag7, ma7_cases = ma7, ma14_cases = ma14, cases_per_100k = cases_pk)
  if("tests_per_100k" %in% names(df_model)) vec <- c(vec, tests_per_100k = tail(prev_window$tests_per_100k,1))
  
  pred_i <- predict(model, xgb.DMatrix(matrix(as.numeric(vec), nrow=1)))
  future$pred[i] <- pred_i
  
  new_row <- prev_window[1,]
  new_row[] <- NA
  new_row$new_cases <- pred_i
  new_row$cases_per_100k <- cases_pk
  if("tests_per_100k" %in% names(prev_window)) new_row$tests_per_100k <- tail(prev_window$tests_per_100k,1)
  prev_window <- rbind(prev_window, new_row)
}

future

ggplot() +
  geom_line(data = df_model %>% tail(60), aes(x=date, y=new_cases)) +
  geom_line(data = future, aes(x=date, y=pred)) +
  labs(title=paste("Forecast", h, "días -", pais), y="Nuevos casos", x="Fecha") + 
  theme_minimal()

fwrite(future, file=paste0("forecast_", pais, "_", h, "d.csv"))
```

# Conclusion
- En este trabajo se realizó un análisis completo de la evolución de los nuevos casos diarios de COVID-19 en Argentina, utilizando el dataset de Our World in Data. A partir de la exploración inicial se observó que los casos presentan una marcada variabilidad temporal, con picos pronunciados y períodos de baja actividad, lo cual es característico de procesos epidemiológicos sujetos a olas de contagio, cambios en políticas sanitarias y comportamiento social.
- Luego, se evaluó la relación entre los tests diarios y los nuevos casos, aplicando un modelo de regresión lineal simple. Si bien el modelo permitió estimar una relación positiva entre ambas variables, el análisis de los coeficientes, el valor p y el R² mostró que la cantidad de tests influye, pero no explica por completo la variación en los contagios. Esto indica que los casos dependen de múltiples factores adicionales (movilidad, variantes, vacunación, políticas públicas, etc.), por lo que una regresión lineal resulta limitada para la predicción.
- Para capturar mejor la dinámica temporal, se construyeron variables rezagadas (lags) y promedios móviles, permitiendo incorporar información del propio comportamiento previo de la serie. Con estas variables se entrenó un modelo de XGBoost optimizado mediante división temporal en train, validation y test, respetando el orden cronológico de los datos. Los resultados en validación y prueba mostraron un desempeño más sólido y estable que el modelo lineal, especialmente para predicciones a corto plazo.
- Finalmente, se generó una predicción a 14 días usando un enfoque iterativo. El modelo logró aproximar la tendencia general reciente, aunque, como es esperable en series epidemiológicas, la incertidumbre aumenta conforme se proyecta más hacia adelante.

---